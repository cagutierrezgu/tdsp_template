# -*- coding: utf-8 -*-
"""data_exploring.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12TzsWbkHj6d_R0ZBmohTLeVnOEnVIqC_

# Preprocesamiento y exploración de los datos

Una vez cargados los datos en el ambiente de Python (archivo data_loading.py o data_loading.ipynb) se realizará el debido preprocesamiento de estos junto con una primera exploración de los mismos para encontrar algunas de características que resulten útiles para la posterior implementación de modelos de aprendizaje automático.

En primer lugar, se importan las librerías necesarias para este script, así como el archivo .py de la adquisición de los datos
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import sklearn
import data_loading as data;

"""A continuación se usa la función *dataload* definida en el script de carga de datos para obtener los datos a partir del link que contiene el archivo"""

link = 'https://drive.google.com/uc?export=download&id=1oOgj9f5UTITTDzMehEIIzNz2aoR2IlgZ'
name = 'stars.csv'
df_stars = data.dataload(link, name)

"""Verificamos que se hizo una correcta carga de los datos mostrando algunos datos del dataframe"""

df_stars.head(5)

"""Antes de continuar, se guardan en un diccionario las etiquetas para cada tipo de estrella, las variables a predecir en los modelos posteriores"""

Nombres = {0:'Brown Dwarf',1:'Red Dwarf',2:'White Dwarf',3:'Main Sequence',4:'Supergiant',5:'Hypergiant'}

"""Una de las primeras acciones a realizar con los datos es conocer la naturaleza de estos, para lo que vemos el tipo de variable de cada columna y la posible existencia de datos faltantes"""

df_stars.dtypes

df_stars.isna().sum()

"""Lo anterior deja ver que no existen datos faltantes, por lo que no habrá necesidad de eliminación de filas o columnas de datos ni imputación de estos. Por otro lado, existen 2 variables tipo 'object' que como se verá más adelante corresponden a variables categóricas.

Continuando con características generales del dataframe, observamos algunas cantidades estadísticas de cada columna
"""

df_stars.describe()

"""Así mismo, una herramienta útil para descubrir posibles relaciones entre las variables es haciendo un mapa de calor de las correlaciones entre cada columna como se ve en la siguiente figura"""

fig, ax = plt.subplots(figsize = (7, 6), dpi = 90)
cor = sns.heatmap(df_stars.corr(), xticklabels=df_stars.corr().columns, yticklabels=df_stars.corr().columns,annot = True, ax = ax)
cor.set_title('Correlation');
#plt.savefig('Images/HeatMapCorrelation.png', bbox_inches='tight')
plt.show();
plt.close();

"""Una alta correlación negativa se observa entre las cantidades de la magnitud absoluta y el tipo de estrella. Así mismo, hay otros 4 pares de variables con una correlación absoluta mayor a 0.6, que también deben considerarse.

Por otro lado, observar la distribución de los datos respecto a la variable objetivo de los futuros modelos es importante, para lo cual se realiza la gráfica siguiente
"""

fig, ax = plt.subplots(figsize = (7, 6), dpi = 90)
sns.countplot(df_stars['Star type'], palette = "viridis", ax = ax);

"""Dejando ver una distribución aparentemente perfecta de esta variable. Así mismo, es posible comparar el diagrama de Hertzprung Russell obtenido con las estrellas de este conjunto de datos con el diagrama habitual, mostrado a continuación

<img src=https://upload.wikimedia.org/wikipedia/commons/6/6b/HRDiagram.png>
"""

fig, ax = plt.subplots(1, figsize=(9,6))
GroupedData = df_stars.groupby('Star type')
for GroupName,group in GroupedData:
    ax.scatter(group['Temperature (K)'], group['Luminosity(L/Lo)'],label = Nombres[GroupName])
ax.legend(fontsize = 7.5)
ax.set_xlabel("Temperature (K)")
ax.set_ylabel("Luminosity (L/Lo)")
ax.set_ylim(0.1*df_stars['Luminosity(L/Lo)'].min(),10*df_stars['Luminosity(L/Lo)'].max())
ax.set_title('Hertzprung Russell Diagram')
plt.xscale('log')
plt.yscale('log')
ax.invert_xaxis()
plt.show()
plt.close()

"""Al observar las dos imágenes puede apreciarse la similitud entre ellas; a pesar de que no se vean del todo idénticas, los tipos de estrellas están ubicadas en las regiones correctas del diagrama. Ahora, se analizarán las variables tipo 'object' encontradas más atrás, para lo cual se inicia con su verificación como variables categóricas"""

df_stars['Spectral Class'].unique()

df_stars['Star color'].unique()

"""La columna 'Spectral Class' está debidamente organizada, sin embargo, 'Star Color' posee varios colores iguales escritos de maneras distintas, cosa que debe corregirse. La siguiente es una figura que muestra la problemática que tiene dicha columna"""

plt.figure(figsize = (13, 6))
color = pd.DataFrame(df_stars['Star color'].value_counts().sort_values(ascending=False))
ax = sns.barplot(x = color.index, y = 'Star color' , data = color, palette='magma')
plt.title("Star Colors", fontsize = 18)
plt.ylabel('Star color', fontsize = 15)
plt.xticks(fontsize = 14)
plt.yticks(fontsize = 14)
ax = ax.set_xticklabels(ax.get_xticklabels(), rotation = 90)

"""Para solucionar lo anterior, definimos una función que cambie todos los colores 'repetidos' por uno solo. Además, realizamos one hot encoding para estas variables categóricas, se realiza la partición de los datos en entrenamiento y prueba y se hace un debido reescalamiento de los mismos"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

def preprocess(df):
    df = df.copy()
    
    # Arreglo de colores
    color_mapping = {
        'Blue ': 'Blue',
        'Blue white': 'Blue White',
        'Blue-white': 'Blue White',
        'Blue white ': 'Blue White',
        'Blue-White': 'Blue White',
        'white': 'White',
        'yellow-white': 'Yellowish White',
        'White-Yellow': 'Yellowish White',
        'yellowish': 'Yellowish'
    }
    df['Star color'] = df['Star color'].replace(color_mapping)
    
    # One-hot encoding
    #df = pd.concat([df, pd.get_dummies(df['Star color'], prefix='Color')], axis=1)
    #df = pd.concat([df, pd.get_dummies(df['Spectral Class'], prefix='Class')], axis=1)
    df = df.drop(['Star color', 'Spectral Class'], axis=1)
    
    # Separación de variables
    X = df.drop('Star type', axis=1)
    y = df['Star type']
    
    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=0)

    # Scale X
    scaler = StandardScaler()
    scaler.fit(X_train)
    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)
    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)
    
    return X_train, X_test, y_train, y_test, scaler

"""Los nuevos datos se guardan en variables correspondientes de entrenamiento y prueba para las variables y etiquetas del modelo. A continuación se muestran algunas de dichas variables y la variable objetivo"""

X_train, X_test, y_train, y_test, scaler = preprocess(df_stars)
X_train.head(5)

y_train.head(5)

"""Finalmente, guardamos los datos ya preprocesados, separados y ya listos para implementar modelos de aprendizaje automático como archivos .csv"""

X_train.to_csv('X_train.csv')
X_test.to_csv('X_test.csv')
y_train.to_csv('y_train.csv')
y_test.to_csv('y_test.csv')